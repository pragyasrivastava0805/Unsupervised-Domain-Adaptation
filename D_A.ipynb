{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "D-A.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1eDL7hcp4-VcI6S8di8A0umpRz1DRMvtg",
      "authorship_tag": "ABX9TyNQX8PYHOw14XJFNFtvJOkT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5ae066051fa94b518889358b1ec7dc57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e9cbdf95eadc4a509824c6de0169b951",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f6a7592559994222b76ff14837d6876d",
              "IPY_MODEL_8015c8d92dd145119f83879e8aeb5dc6",
              "IPY_MODEL_bee2ff4d239f4132b05e9eb5ee21350d"
            ]
          }
        },
        "e9cbdf95eadc4a509824c6de0169b951": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f6a7592559994222b76ff14837d6876d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dc315351cb4c498bacd1f90ed99ae2b2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_526d04ba9609497cb68f20b607ef3e7d"
          }
        },
        "8015c8d92dd145119f83879e8aeb5dc6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a7a67f73f47e4120ac381a1ccd961336",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 102530333,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 102530333,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_274c51d288324766b6556f5c45bc4453"
          }
        },
        "bee2ff4d239f4132b05e9eb5ee21350d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_ed4aa16a9b554b70b2dc36d6e76da658",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 97.8M/97.8M [00:01&lt;00:00, 94.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2cf58924330e4eb9bedebb73c1888310"
          }
        },
        "dc315351cb4c498bacd1f90ed99ae2b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "526d04ba9609497cb68f20b607ef3e7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a7a67f73f47e4120ac381a1ccd961336": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "274c51d288324766b6556f5c45bc4453": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ed4aa16a9b554b70b2dc36d6e76da658": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2cf58924330e4eb9bedebb73c1888310": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pragyasrivastava0805/congenial-journey/blob/main/D_A.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8Jj0Llixu2o"
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, datasets\n",
        "import numpy as np\n",
        "import os\n",
        "from torch.utils.data.sampler import SubsetRandomSampler\n",
        "from PIL import Image\n",
        "\n",
        "\n",
        "\n",
        "class OfficeAmazonDataset(Dataset):\n",
        "\n",
        "\n",
        "    def __init__(self, image_folder_dataset, transform=None):\n",
        "        super(OfficeAmazonDataset, self).__init__()\n",
        "        self.image_folder_dataset = image_folder_dataset\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_folder_dataset.imgs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # read image, class from folder_dataset given index\n",
        "        img, img_label = image_folder_dataset[idx][0], image_folder_dataset[idx][1]\n",
        "\n",
        "        # apply transformations (it already returns them as torch tensors)\n",
        "        if self.transform is not None:\n",
        "            self.transform(img)\n",
        "\n",
        "        img_label_pair = {\"image\": img,\n",
        "                         \"class\": img_label}\n",
        "\n",
        "        return img_label_pair\n",
        "\n",
        "\n",
        "def get_dataloader(dataset, batch_size, train_ratio=0.7):\n",
        "\n",
        "\n",
        "    def get_subset(indices, start, end):\n",
        "        return indices[start:start+end]\n",
        "\n",
        "    # Split train/val data ratios\n",
        "    TRAIN_RATIO, VALIDATION_RATIO = train_ratio, 1-train_ratio\n",
        "    train_set_size = int(len(dataset) * TRAIN_RATIO)\n",
        "    validation_set_size = int(len(dataset) * VALIDATION_RATIO)\n",
        "\n",
        "    # Generate random indices for train and val sets\n",
        "    indices = torch.randperm(len(dataset))\n",
        "    train_indices = get_subset(indices, 0, train_set_size)\n",
        "    validation_indices = get_subset(indices,train_set_size,validation_set_size)\n",
        "    # test_indices = get_subset(indices,train_count+validation_count,len(dataset))\n",
        "\n",
        "    # Create sampler objects\n",
        "    train_sampler = SubsetRandomSampler(train_indices)\n",
        "    val_sampler = SubsetRandomSampler(validation_indices)\n",
        "\n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                              sampler=train_sampler, num_workers=0)\n",
        "\n",
        "    val_loader = DataLoader(dataset, batch_size=batch_size,\n",
        "                            sampler=val_sampler, num_workers=0)\n",
        "\n",
        "    return train_loader, val_loader\n",
        "\n",
        "\n",
        "def get_office_data(name_dataset):\n",
        "\n",
        "\n",
        "    \n",
        "    root_dir = \"/content/drive/My Drive/Original_images/Original_images\" .format(name_dataset)\n",
        "\n",
        "    __datasets__ = [\"amazon\", \"dslr\", \"webcam\"]\n",
        "\n",
        "    if name_dataset not in __datasets__:\n",
        "        raise ValueError(\"must introduce one of the three datasets in office\")\n",
        "\n",
        "    mean_std = {\n",
        "        \"amazon\":{\n",
        "            \"mean\":[0.7923, 0.7862, 0.7841],\n",
        "            \"std\":[0.3149, 0.3174, 0.3193]\n",
        "        },\n",
        "        \"dslr\":{\n",
        "            \"mean\":[0.4708, 0.4486, 0.4063],\n",
        "            \"std\":[0.2039, 0.1920, 0.1996]\n",
        "        },\n",
        "        \"webcam\":{\n",
        "            \"mean\":[0.6119, 0.6187, 0.6173],\n",
        "            \"std\":[0.2506, 0.2555, 0.2577]\n",
        "        }\n",
        "    }\n",
        "\n",
        "    # compose image transformations\n",
        "    data_transforms = transforms.Compose([\n",
        "            transforms.Resize((227, 227)),\n",
        "            transforms.CenterCrop(227),\n",
        "            # transforms.RandomSizedCrop(224),\n",
        "            # transforms.RandomHorizontalFlip(),\n",
        "            transforms.ToTensor(),\n",
        "            transforms.Normalize(mean=mean_std[name_dataset][\"mean\"],\n",
        "                                 std=mean_std[name_dataset][\"std\"])\n",
        "        ])\n",
        "\n",
        "    # retrieve dataset using ImageFolder\n",
        "    # datasets.ImageFolder() command expects our data to be organized\n",
        "    # in the following way: root/label/picture.png\n",
        "    dataset = datasets.ImageFolder(root=root_dir,\n",
        "                                   transform=data_transforms)\n",
        "    # Dataloader is able to spit out random samples of our data,\n",
        "    # so our model won’t have to deal with the entire dataset every time.\n",
        "    # shuffle data when training\n",
        "  \n",
        "    return dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TXxOoiALxa4S"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SMim_TaOyP4t"
      },
      "source": [
        "source_train_loader,source_val_loader=get_dataloader(get_office_data(\"amazon\"),batch_size=64,train_ratio=0.70)\n",
        "target_train_loader,target_val_loader=get_dataloader(get_office_data(\"dslr\"),batch_size=64,train_ratio=0.70)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBr5mpT8yYAU"
      },
      "source": [
        "from torch.autograd import Function\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "class ReverseLayerF(Function):\n",
        "\n",
        "    @staticmethod\n",
        "    def forward(ctx, x, alpha):\n",
        "        ctx.alpha = alpha\n",
        "\n",
        "        return x.view_as(x)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        output = grad_output.neg() * ctx.alpha\n",
        "\n",
        "        return output, None\n",
        "\n",
        "class ResNet50(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ResNet50, self).__init__()\n",
        "        \n",
        "        resnetModel = models.resnet50(pretrained=True)\n",
        "        feature_map = list(resnetModel.children())\n",
        "        feature_map.pop()\n",
        "        for layers in feature_map:\n",
        "          layers.trainable=False\n",
        "        self.feature_extractor = nn.Sequential(*feature_map)\n",
        "\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(2048, 31),\n",
        "        )\n",
        "\n",
        "        self.discriminator = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(),\n",
        "            nn.Linear(1024, 32),\n",
        "        )\n",
        "\n",
        "    def forward(self, input_data, alpha):\n",
        "        input_data = input_data.expand(input_data.data.shape[0], 3, 227, 227)\n",
        "        feature = self.feature_extractor(input_data)\n",
        "        feature = feature.view(-1, 2048)\n",
        "        print(feature)\n",
        "        print(len(feature))\n",
        "\n",
        "        reverse_bottleneck = ReverseLayerF.apply(feature, alpha)\n",
        "\n",
        "        class_output = self.classifier(feature)\n",
        "        domain_output = self.discriminator(reverse_bottleneck)\n",
        "\n",
        "        return class_output, domain_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kT1D-5cDyd5B"
      },
      "source": [
        "def test(dataloader):\n",
        "    len_dataloader = len(dataloader)\n",
        "    data_target_iter = iter(dataloader)\n",
        "\n",
        "    i = 0\n",
        "    n_total = 0\n",
        "    n_correct = 0\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        # test model using target data\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, t_label = data_target\n",
        "\n",
        "        batch_size = len(t_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "\n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "        class_label.resize_as_(t_label).copy_(t_label)\n",
        "\n",
        "        class_output, _ = my_net(input_data=input_img, alpha=alpha)\n",
        "        pred = class_output.data.max(1, keepdim=True)[1]\n",
        "        n_correct += pred.eq(class_label.data.view_as(pred)).cpu().sum()\n",
        "        n_total += batch_size\n",
        "\n",
        "        i += 1\n",
        "    accu = n_correct.data.numpy() * 1.0 / n_total\n",
        "    return accu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442,
          "referenced_widgets": [
            "5ae066051fa94b518889358b1ec7dc57",
            "e9cbdf95eadc4a509824c6de0169b951",
            "f6a7592559994222b76ff14837d6876d",
            "8015c8d92dd145119f83879e8aeb5dc6",
            "bee2ff4d239f4132b05e9eb5ee21350d",
            "dc315351cb4c498bacd1f90ed99ae2b2",
            "526d04ba9609497cb68f20b607ef3e7d",
            "a7a67f73f47e4120ac381a1ccd961336",
            "274c51d288324766b6556f5c45bc4453",
            "ed4aa16a9b554b70b2dc36d6e76da658",
            "2cf58924330e4eb9bedebb73c1888310"
          ]
        },
        "id": "RNkmf_Nkyi_o",
        "outputId": "11e3eec5-79a8-4162-fdeb-957c27f6a044"
      },
      "source": [
        "lr = 1e-3\n",
        "n_epoch=10\n",
        "my_net = ResNet50()\n",
        "import torch.optim as optim\n",
        "optimizer = optim.Adam(my_net.parameters(), lr=lr)\n",
        "image_size=227\n",
        "acc1=[]\n",
        "acc2=[]\n",
        "\n",
        "loss_class = torch.nn.CrossEntropyLoss()\n",
        "loss_domain = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "for p in my_net.parameters():\n",
        "    p.requires_grad = True\n",
        "for epoch in range(n_epoch):\n",
        "\n",
        "    len_dataloader = min(len(source_train_loader), len(target_train_loader))\n",
        "    data_source_iter = iter(source_train_loader)\n",
        "    data_target_iter = iter(target_train_loader)\n",
        "\n",
        "    i = 0\n",
        "    while i < len_dataloader:\n",
        "\n",
        "        \n",
        "        alpha = 1\n",
        "\n",
        "        # training model using source data\n",
        "        data_source = data_source_iter.next()\n",
        "        s_img, s_label = data_source\n",
        "      \n",
        "        my_net.zero_grad()\n",
        "        batch_size = len(s_label)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        class_label = torch.LongTensor(batch_size)\n",
        "    \n",
        "\n",
        "     \n",
        "\n",
        "        input_img.resize_as_(s_img).copy_(s_img)\n",
        "        class_label.resize_as_(s_label).copy_(s_label)\n",
        "\n",
        "        class_output, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
        "        err_s_label = loss_class(class_output, class_label)\n",
        "        err_s_domain = loss_domain(domain_output, class_label)\n",
        "\n",
        "        # training model using target data\n",
        "        data_target = data_target_iter.next()\n",
        "        t_img, _ = data_target\n",
        "\n",
        "        batch_size = len(t_img)\n",
        "\n",
        "        input_img = torch.FloatTensor(batch_size, 3, image_size, image_size)\n",
        "        domain_label = torch.full((batch_size,1),31)\n",
        "        domain_label.squeeze_()\n",
        "\n",
        "      \n",
        "\n",
        "        input_img.resize_as_(t_img).copy_(t_img)\n",
        "\n",
        "        _, domain_output = my_net(input_data=input_img, alpha=alpha)\n",
        "        err_t_domain = loss_domain(domain_output, domain_label)\n",
        "        err = (err_t_domain + err_s_domain)/(len(source_train_loader)+len(target_train_loader)) + err_s_label/(len(source_train_loader))\n",
        "        err.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        i += 1\n",
        "    print(epoch,n_epoch, err_s_label.cpu().data.numpy(),err_s_domain.cpu().data.numpy(), err_t_domain.cpu().data.numpy())\n",
        "    acc1.append(test(source_val_loader))\n",
        "    acc2.append(test(target_val_loader))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5ae066051fa94b518889358b1ec7dc57",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0.00/97.8M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.0622, 0.4434, 0.1521,  ..., 0.3045, 0.4773, 0.5086],\n",
            "        [1.2466, 0.2449, 0.4218,  ..., 0.0000, 0.4486, 0.0170],\n",
            "        [0.0367, 0.1776, 0.1010,  ..., 0.3550, 0.2759, 0.2112],\n",
            "        ...,\n",
            "        [0.5981, 0.1166, 0.2106,  ..., 0.3958, 0.3545, 0.0724],\n",
            "        [0.3216, 0.2099, 0.1492,  ..., 0.5383, 0.3712, 0.1443],\n",
            "        [0.2074, 0.0617, 0.3631,  ..., 0.2073, 0.1118, 0.0918]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "64\n",
            "tensor([[0.4396, 0.0824, 0.7063,  ..., 0.1727, 0.2310, 0.3989],\n",
            "        [0.2282, 0.6209, 0.5985,  ..., 0.4675, 0.1473, 0.2574],\n",
            "        [0.0595, 0.4570, 0.0397,  ..., 0.1211, 0.2876, 0.7566],\n",
            "        ...,\n",
            "        [0.6887, 1.6375, 0.4238,  ..., 0.1931, 0.4082, 0.5428],\n",
            "        [0.9403, 0.1159, 0.4234,  ..., 0.0303, 0.4586, 0.0667],\n",
            "        [0.0403, 0.2393, 0.1424,  ..., 0.3090, 0.0527, 0.2363]],\n",
            "       grad_fn=<ViewBackward>)\n",
            "64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sq9d8FiUyoBS"
      },
      "source": [
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "epsilon=np.arange(0,10,1)\n",
        "plt.plot(epsilon,acc1,color='r',label='Source Test Accuracy')\n",
        "plt.plot(epsilon,acc2,color='g',label='Target Test Accuracy')\n",
        "\n",
        "plt.xlabel(\"Epsilon\")\n",
        "\n",
        "\n",
        "\n",
        "plt.ylabel(\"Accuracies\")\n",
        "plt.title(\"Test Accuracies\")\n",
        "plt.legend()\n",
        "  \n",
        "\n",
        "plt.show()\n",
        "print(acc1[len(acc1)-1],acc2[len(acc2)-1])  "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}